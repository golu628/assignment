{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyr6aV6eZhR6Z08Fk9PUWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/golu628/assignment/blob/main/Untitled62.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXPuU0N_FGYh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Bayes' theorem?\n",
        "\n",
        "Bayes' theorem is a mathematical formula in probability and statistics used to calculate the conditional probability of an event occurring given that another event has already happened. In simpler terms, it allows you to update the probability of something being true based on new evidence.\n",
        "\n",
        "Q2. What is the formula for Bayes' theorem?\n",
        "\n",
        "The formula for Bayes' theorem is:\n",
        "\n",
        "P(A | B) = (P(B | A) * P(A)) / P(B)\n",
        "P(A | B): The probability of event A occurring given that event B has already happened (what we want to find).\n",
        "P(B | A): The probability of event B occurring given that event A has already happened.\n",
        "P(A): The prior probability of event A happening (initial belief about A before considering B).\n",
        "P(B): The probability of event B happening (regardless of A).\n",
        "Q3. How is Bayes' theorem used in practice?\n",
        "\n",
        "Bayes' theorem has a wide range of applications in various fields, including:\n",
        "\n",
        "Spam filtering: Classifying emails as spam or not spam based on keywords and other factors.\n",
        "Medical diagnosis: Updating the diagnosis of a disease based on new test results.\n",
        "Machine learning: Building classifiers for various tasks, such as sentiment analysis or image recognition.\n",
        "Risk assessment: Evaluating the likelihood of an event happening (e.g., financial risk, creditworthiness).\n",
        "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
        "\n",
        "Bayes' theorem directly deals with conditional probability. It provides a way to calculate the probability of one event (A) given the occurrence of another event (B).\n",
        "\n",
        "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
        "\n",
        "Naive Bayes classifiers are a type of classifier based on Bayes' theorem that assumes independence between features. The choice of a specific Naive Bayes classifier depends on the nature of your problem and the data you have:\n",
        "\n",
        "Multinomial Naive Bayes: Suitable for discrete features (e.g., word counts in text documents).\n",
        "Gaussian Naive Bayes: Works well for continuous features that are assumed to be normally distributed (Gaussian).\n",
        "Bernoulli Naive Bayes: Designed for binary features (e.g., presence or absence of a word).\n",
        "Consider the distribution of your features and the types of data you're working with when choosing the appropriate Naive Bayes variant.\n",
        "\n",
        "Q6. Assignment:\n",
        "\n",
        "Scenario:\n",
        "\n",
        "You have a dataset with two features, X1 and X2, and two possible classes, A and B.\n",
        "You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4.\n",
        "The table shows the frequency of each feature value for each class:\n",
        "| Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4 |\n",
        "|---|---|---|---|---|---|---|\n",
        "| A | 3 | 3 | 4 | 4 | 3 | 3 | 3 |\n",
        "| B | 2 | 2 | 1 | 2 | 2 | 2 | 3 |\n",
        "\n",
        "Solution using Naive Bayes with equal prior probabilities:\n",
        "\n",
        "Calculate class probabilities: Since we're assuming equal prior probabilities for A and B, both classes have a probability of P(A) = P(B) = 1/2.\n",
        "\n",
        "Calculate class-conditional probabilities:\n",
        "\n",
        "P(X1=3 | A) = Frequency of X1=3 in class A / Total instances in class A = 4 / 17\n",
        "P(X2=4 | A) = Frequency of X2=4 in class A / Total instances in class A = 3 / 17\n",
        "P(X1=3 | B) = Frequency of X1=3 in class B / Total instances in class B = 1 / 7\n",
        "P(X2=4 | B) = Frequency of X2=4 in class B / Total instances in class B = 3 / 7\n",
        "Calculate posterior probabilities:\n",
        "\n",
        "P(A | X1=3, X2=4) = (P(X1=3 | A) * P(X2=4 | A) * P(A)) / P(X1=3, X2=4)\n",
        "P(B | X1=3, X2=4) = (P(X1=3 | B) * P(X2=4 | B) * P\n",
        "\n",
        "\n",
        "\n",
        "tune\n",
        "\n",
        "share\n",
        "\n",
        "\n",
        "more_vert\n"
      ],
      "metadata": {
        "id": "vlKKjApyH6wN"
      }
    }
  ]
}